{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier           \n",
    "from sklearn.neighbors import KNeighborsClassifier            \n",
    "from sklearn.ensemble import GradientBoostingClassifier       \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "#from sklearn.model_selection import GridSearchCV \n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "from random import seed\n",
    "from random import randint\n",
    "\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abro el texto donde están los datos \n",
    "encuesta=pd.read_csv(\"../trabajo final macroencuesta/DA3242\",delimiter= '\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gracias al libro de códigos, se crea  un diccionario con el nombre de las columnas y donde se realizan los cortes, para crear el DataFrame \n",
    "columnas={\"ESTU\": [1,4], \"CUES\": [5,9], \"CCAA\":[10,11], \"PROV\": [12,13], \"MUN\": [14,16], \"TAMUNI\": [17,17], \"CAPITAL\": [18,18], \"DISTR\": [19,20], \"SECCION\": [21,23],\"ENTREV\": [24,27], \"P0A\": [28,28], \"P1\": [29,29], \"P2\": [30,30], \"P3\": [31,31], \"P4\": [32,32], \"P501\": [33,33], \"P502\": [34,34], \"P503\": [35,35], \"P601\": [36,37], \"P602\": [38,39], \"P603\": [40,41],\"P701\": [42,43], \"P702\": [44,45], \"P703\": [46,47], \"P801\": [48,48], \"P802\": [49,49], \"P803\": [50,50], \"P804\": [51,51], \"P805\": [52,52], \"P806\": [53,53], \"P807\": [54,54], \"P808\": [55,55],\"P809\": [56,56], \"P810\": [57,57], \"P811\": [58,58], \"P812\": [59,59], \"P813\": [60,60], \"P814\":[61,61], \"P815\": [62,62], \"P816\": [63,63], \"P9\": [64,64], \"P9A\":[65,65], \"P9B01\": [66,67], \"P9B02\": [68,69],\"P10\": [70,71], \"P10A\": [72,73], \"P1101\": [74,75], \"P1102\": [76,77], \"P1103\": [78,79], \"P1104\": [80,81], \"P1105\": [82,83], \"P1106\": [84,85],\"P12\":[86,87], \"P1301\": [88,89], \"P1302\": [90,91], \"P1303\": [92,93], \"P1304\": [94,95], \"P1305\": [96,97], \"P1306\": [98,99], \"P1307\": [100,101],\"P1308\": [102,103], \"P1309\": [104,105], \"P1310\": [106,107], \"P1311\": [108,109], \"P1312\": [110,111], \"P1313\": [112,113], \"P1314\": [114,115],\"P1315\": [116,117], \"P1316\": [118,119], \"P1317\": [120,121], \"P1318\": [122,123], \"P1319\": [124,125], \"P1320\": [126,127], \"P14\": [128,129],\"P15\": [130,131], \"P16\": [132,133], \"P17\": [134,135], \"P18\": [136,136], \"P18A\": [137,138], \"P19\": [139,140], \"P2001\": [141,142], \"P2002\": [143,144],\"P2003\": [145,146], \"P2004\" :[147,148], \"P2005\": [149,150], \"P2006\": [151,152], \"P2007\": [153,154], \"P2008\": [155,156],\"P2009\": [157,158],\"P2010\": [159,160], \"P2011\": [161,162], \"P2012\": [163,164], \"P2013\": [165,166], \"P2014\": [167,168], \"P2015\": [169,170], \"P2016\": [171,172],\"P2017\": [173,174], \"P2018\": [175,176], \"P2019\": [177,178], \"P2020\": [179,180], \"P21\": [181,182], \"P21A\": [183,184], \"P22\": [185,185], \"P23\": [186,187],\"P24\": [188,188], \"P24A\": [189,190], \"P25\": [191,191], \"P25A\":[192,193], \"P26\":[194,194], \"P27\": [195,195], \"P28\": [196,196], \"P29\": [197,197], \"P30\": [198,198], \"P30A\": [199,199], \"P31\":[200,200],\"E101\": [201,202], \"E102\": [203,204], \"E103\": [205,206], \"E2\": [207,209], \"E3\": [210,210], \"C1\": [211,211], \"C1A\": [212,213], \"PESO\": [214,220],\"P9BCOMR\": [221,224], \"P10R\": [225,226], \"P10AR\": [227,228], \"VOTOSIMG\": [229,230], \"P18AR\": [231,232], \"RECUERDO\": [233,234], \"P9BCOM\": [235,238],\"P14R\": [239,240], \"P15R\": [241,242], \"P16R\": [243,244], \"ESTUDIOS\": [245,245], \"PESOCCAA\": [246,252]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>P1307</th>\n",
       "      <th>P812</th>\n",
       "      <th>P14</th>\n",
       "      <th>P1315</th>\n",
       "      <th>P19</th>\n",
       "      <th>P806</th>\n",
       "      <th>P30</th>\n",
       "      <th>P1302</th>\n",
       "      <th>P10AR</th>\n",
       "      <th>...</th>\n",
       "      <th>P1320</th>\n",
       "      <th>P1102</th>\n",
       "      <th>P2004</th>\n",
       "      <th>P810</th>\n",
       "      <th>P18A</th>\n",
       "      <th>P9A</th>\n",
       "      <th>ENTREV</th>\n",
       "      <th>P27</th>\n",
       "      <th>P2003</th>\n",
       "      <th>P503</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3242    116 1 5951 0  0   01124321313 818 8121...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>98</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3242    216 1 5951 0  0   012333128 11898 1451...</td>\n",
       "      <td>98</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3242    316 1 5951 0  0   014454799 1192219229...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>97</td>\n",
       "      <td></td>\n",
       "      <td>98</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3242    416 1 5951 0  0   01133317919 198 1 91...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3242    516 1 5951 0  0   099939138 1181212189...</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>98</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 136 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0 P1307 P812 P14 P1315 P19  \\\n",
       "0  3242    116 1 5951 0  0   01124321313 818 8121...     0    8   2         4   \n",
       "1  3242    216 1 5951 0  0   012333128 11898 1451...    98    8   1         6   \n",
       "2  3242    316 1 5951 0  0   014454799 1192219229...     0    5  97        98   \n",
       "3  3242    416 1 5951 0  0   01133317919 198 1 91...     1    8   3         4   \n",
       "4  3242    516 1 5951 0  0   099939138 1181212189...     1    8   5         4   \n",
       "\n",
       "  P806 P30 P1302 P10AR  ... P1320 P1102 P2004 P810 P18A P9A ENTREV P27 P2003  \\\n",
       "0    4   2     3    98  ...           1     6    4    2   9      0   1     3   \n",
       "1    5   2     2     0  ...           6     6    5    1   1      0   1     1   \n",
       "2    5   2     0    97  ...           1    98    5    0   0      0   1    98   \n",
       "3    8   2     5     0  ...           1     6    4    0   0      0   2     3   \n",
       "4    3   2     3    98  ...           5     5    5    0   0      0   1     3   \n",
       "\n",
       "  P503  \n",
       "0    3  \n",
       "1    8  \n",
       "2    9  \n",
       "3    9  \n",
       "4    8  \n",
       "\n",
       "[5 rows x 136 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#se aplican los intervalos del diccionario en el DataFrame que hemos obtenido para poder crear las columnas\n",
    "def get_intervals(x, a, b): \n",
    "    try: \n",
    "        return x[a:b]\n",
    "    except: \n",
    "        print(x, a, b)\n",
    "\n",
    "for a in columnas:\n",
    "    encuesta[a] = encuesta[0].apply(lambda x: get_intervals(x, columnas[a][0]-1, columnas[a][1]))\n",
    "encuesta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminamos la columna 0, dado que ya no nos sirve\n",
    "def drop_columna(data,columna,axis=1,inplace=True):\n",
    "    return data.drop(columna, axis=1, inplace=True)\n",
    "drop_columna(encuesta,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P1307</th>\n",
       "      <th>P812</th>\n",
       "      <th>P14</th>\n",
       "      <th>P1315</th>\n",
       "      <th>P19</th>\n",
       "      <th>P806</th>\n",
       "      <th>P30</th>\n",
       "      <th>P1302</th>\n",
       "      <th>P10AR</th>\n",
       "      <th>PROV</th>\n",
       "      <th>...</th>\n",
       "      <th>P1320</th>\n",
       "      <th>P1102</th>\n",
       "      <th>P2004</th>\n",
       "      <th>P810</th>\n",
       "      <th>P18A</th>\n",
       "      <th>P9A</th>\n",
       "      <th>ENTREV</th>\n",
       "      <th>P27</th>\n",
       "      <th>P2003</th>\n",
       "      <th>P503</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 135 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   P1307  P812  P14  P1315  P19  P806  P30  P1302  P10AR  PROV  ...  P1320  \\\n",
       "0      0     8    2      0    4     4    2      3     98     1  ...      0   \n",
       "1     98     8    1      0    6     5    2      2      0     1  ...      0   \n",
       "2      0     5   97      0   98     5    2      0     97     1  ...      0   \n",
       "3      1     8    3      0    4     8    2      5      0     1  ...      0   \n",
       "4      1     8    5      0    4     3    2      3     98     1  ...      0   \n",
       "\n",
       "   P1102  P2004  P810  P18A  P9A  ENTREV  P27  P2003  P503  \n",
       "0      1      6     4     2    9       0    1      3     3  \n",
       "1      6      6     5     1    1       0    1      1     8  \n",
       "2      1     98     5     0    0       0    1     98     9  \n",
       "3      1      6     4     0    0       0    2      3     9  \n",
       "4      5      5     5     0    0       0    1      3     8  \n",
       "\n",
       "[5 rows x 135 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convertimos las columnas en numericas \n",
    "def get_numeric(x):\n",
    "    try:\n",
    "        return int(x)\n",
    "    except:\n",
    "        return 0\n",
    "for a in columnas:\n",
    "    encuesta[a] = encuesta[a].apply(get_numeric)\n",
    "    \n",
    "encuesta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seleccionamos las columnas que no nos interesan y las eliminamos\n",
    "columnas_para_eliminar=(\"ESTU\",\"CUES\",\"PROV\",\"MUN\",\"DISTR\",\"SECCION\",\"ENTREV\",\"P501\",\"P502\",\"P503\",\"P601\",\"P602\",\"P603\",\"P701\",\"P702\",\"P703\",\"P805\",\"P806\",\"P807\",\"P808\",\"P809\",\"P810\",\"P811\",\"P812\",\"P813\",\"P814\",\"P815\",\"P816\",\"P9\",\"P9A\",\"P9B01\",\"P9B02\",\"P10\",\"P1101\",\"P1102\",\"P1103\",\"P1104\",\"P1105\",\"P1106\",\"P1305\",\"P1306\",\"P1307\",\"P1308\",\"P1309\",\"P1310\",\"P1311\",\"P1312\",\"P1313\",\"P1314\",\"P1315\",\"P1316\",\"P1317\",\"P1318\",\"P1319\",\"P1320\",\"P14\",\"P15\",\"P16\",\"P17\",\"P18\",\"P18A\",\"P2005\",\"P2006\",\"P2007\",\"P2008\",\"P2009\",\"P2010\",\"P2011\",\"P2012\",\"P2013\",\"P2014\",\"P2015\",\"P2016\",\"P2017\",\"P2018\",\"P2019\",\"P2020\",\"P21\",\"P21A\",\"P24A\",\"P25A\",\"P29\",\"P30\",\"P30A\",\"P31\",\"E101\",\"E102\",\"E103\",\"E2\",\"E3\",\"C1\",\"C1A\",\"VOTOSIMG\",\"RECUERDO\",\"P9BCOM\",\"P15R\",\"P16R\",\"P10AR\",\"P9BCOMR\",\"P10A\",\"P24\",\"P10R\",\"P12\",\"P18AR\",\"PESO\",\"PESOCCAA\")\n",
    "for a in columnas_para_eliminar:\n",
    "    drop_columna(encuesta,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se crean listas para ordenar el DataFrame\n",
    "cols=[\"P1\",\"P2\",\"P3\",\"P4\",\"P801\",\"P802\",\"P803\",\"P804\",\"P1301\",\"P1302\",\"P1303\",\"P1304\",\"P2001\",\"P2002\",\"P2003\",\"P2004\",\"P23\",\"TAMUNI\",\"ESTUDIOS\",\"CAPITAL\",\"CCAA\",\"P0A\",\"P14R\",\"P22\",\"P25\",\"P26\",\"P27\",\"P28\",\"P19\"]\n",
    "colssincat=[\"P1\",\"P2\",\"P3\",\"P4\",\"P801\",\"P802\",\"P803\",\"P804\",\"P1301\",\"P1302\",\"P1303\",\"P1304\",\"P2001\",\"P2002\",\"P2003\",\"P2004\",\"P23\",\"TAMUNI\",\"ESTUDIOS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ordenamos el DataFrame\n",
    "encuesta = encuesta[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Al ser una encuesta no existen valores nulos, en el sentido de no dato, pero si que existen valores como NS o NC.\n",
    "#que son los que se entenderian por nulos, el problema es que la codificación puede ser por el valor 9 o 99 para NS\n",
    "#por lo que se debe de especificar cada variable según sea la codificación\n",
    "limpieza9=(\"ESTUDIOS\",\"P0A\",\"P1\",\"P2\",\"P3\",\"P4\",\"P801\",\"P802\",\"P803\",\"P804\",\"P23\",\"P25\",\"P26\",\"P27\",\"P28\")\n",
    "limpieza99=(\"P1301\",\"P1302\",\"P1303\",\"P1304\",\"P14R\",\"P2001\",\"P2002\",\"P2003\",\"P2004\",\"P19\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion para quitar los datos según el valor de una columna\n",
    "def drop_file(data,pregunta,valor):\n",
    "    data = data[data[pregunta] != valor]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se eliminan los NC-8 ó 88 y NS - 9 ó 99 de las variables\n",
    "for a in limpieza9:\n",
    "    encuesta = drop_file(encuesta,a,8)\n",
    "    encuesta = drop_file(encuesta,a,9)\n",
    "for a in limpieza99:\n",
    "    encuesta = drop_file(encuesta,a,88)\n",
    "    encuesta = drop_file(encuesta,a,98)\n",
    "    encuesta = drop_file(encuesta,a,99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se eliminan de la columna \"ESTUDIOS\", \"7\" que es otros\n",
    "encuesta = drop_file(encuesta,\"ESTUDIOS\",7)\n",
    "encuesta.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se reordenan el indice, dado que con las eliminaciones se ha desorganizado \n",
    "encuesta=encuesta.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se recodifica  la variable P19, en 3 categorias 0=Izquierda,1=Centro,2=Derecha\n",
    "etiquetas=[1,2,3,4,5]\n",
    "cortes = [0,3,6,10]\n",
    "encuesta[\"ideologia\"] = pd.cut(encuesta['P19'],cortes, labels=etiquetas)\n",
    "encuesta[\"ideologia\"] = pd.to_numeric(encuesta[\"ideologia\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminamos la columna \"P19\", para que no cree ruido e \"index\" que se creó al hacer el reindex\n",
    "encuesta=encuesta.drop(columns=\"P19\")\n",
    "encuesta=encuesta.drop(columns=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creamos en variables dummies las preguntas categoricas, eliminando la primera variable\n",
    "encuesta_dum=pd.get_dummies(encuesta,columns=[\"CAPITAL\",\"CCAA\",\"P0A\",\"P14R\",\"P22\",\"P23\",\"P25\",\"P26\",\"P27\",\"P28\",\"ESTUDIOS\"],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#realizo un PCA para visualizar como es la distribucción de todas las variables en un plano de dos ejes\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "pca = PCA(n_components=2)\n",
    "distribution_all=pca.fit(encuesta_dum.T) \n",
    "plt.figure(figsize=(8,8))\n",
    "color= ['red' if ideologia == 0 \n",
    "        else 'orange' if ideologia == 1\n",
    "        else 'yellow' if ideologia == 2\n",
    "        else 'green' if ideologia == 3\n",
    "        else 'black' if ideologia == 4\n",
    "        else 'green' for ideologia in list(encuesta['ideologia'])]\n",
    "plt.scatter(distribution_all.components_[0], distribution_all.components_[1],color=color,s=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#veo la matriz de correlaciones, el problema es que existen correlaciones que pueden ser altas entre variables\n",
    "#que han sido obtenidas de la categorización por lo que no se pueden eliminar\n",
    "correlacion = encuesta_dum.corr()\n",
    "fig, ax = plt.subplots(figsize = (25,25))\n",
    "ax = sns.heatmap(correlacion, annot=True)\n",
    "ax'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion para ver el número de elementos que tienen colinealidad entre las variables\n",
    "def variablescolinealidad(data):\n",
    "    columns_to_drop=[]                  \n",
    "    for c in data.columns:\n",
    "        for i in range(len(data.corr())):\n",
    "            if abs(data.corr()[c][i])>0.9 and abs(data.corr()[c][i])<1:columns_to_drop.append(c)\n",
    "    columns_to_drop=list(set(columns_to_drop))   \n",
    "    return len(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variablescolinealidad(encuesta_dum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#función para poder realizar los distintos modelos\n",
    "def modelos(data,columnadep):\n",
    "    X=data.loc[:,data.columns!= columnadep]\n",
    "    y=data[columnadep]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "    \n",
    "    #modelos\n",
    "    lr = LogisticRegression(solver ='liblinear',max_iter=500)\n",
    "    cls = svm.SVC(gamma='auto', probability=True)\n",
    "    neigh3 = KNeighborsClassifier(n_neighbors=3)\n",
    "    neigh5 = KNeighborsClassifier(n_neighbors=5)\n",
    "    bosque=RandomForestClassifier(n_estimators=500, criterion='gini')\n",
    "    gnb = GaussianNB()\n",
    "    #tree = tree.DecisionTreeClassifier()\n",
    "    svc = SVC(kernel='rbf', gamma='scale')\n",
    "    gbc=GradientBoostingClassifier()\n",
    "\n",
    "    #entrenando\n",
    "    cls.fit(X_train, y_train)\n",
    "    lr.fit(X_train, y_train)\n",
    "    neigh3.fit(X_train, y_train) \n",
    "    neigh5.fit(X_train, y_train) \n",
    "    bosque.fit(X_train, y_train) \n",
    "    #tree.fit(X_train, y_train)\n",
    "    gnb.fit(X_train,y_train)\n",
    "    svc.fit(X_train,y_train)\n",
    "    gbc.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    y_predlr = lr.predict(X_test)\n",
    "    y_predcls = cls.predict(X_test)\n",
    "    y_pred_neigh3= neigh3.predict(X_test)\n",
    "    y_pred_neigh5= neigh5.predict(X_test)\n",
    "    y_pred_bosque= bosque.predict(X_test)\n",
    "    #y_pred_tree= tree.predict(X_test)\n",
    "    y_pred_gnd = gnb.predict(X_test)\n",
    "    y_pred_svc = svc.predict(X_test)\n",
    "    y_pred_gbc=gbc.predict(X_test)\n",
    "\n",
    "    \n",
    "    print(\"Accuracy lineal:\",metrics.accuracy_score(y_test, y_predcls))\n",
    "    print(\"Accuracy logistics:\",metrics.accuracy_score(y_test, y_predlr))\n",
    "    print(\"Accuracy neigh3:\",metrics.accuracy_score(y_test, y_pred_neigh3))\n",
    "    print(\"Accuracy neigh5:\",metrics.accuracy_score(y_test, y_pred_neigh5))\n",
    "    print(\"Accuracy bosque:\",metrics.accuracy_score(y_test, y_pred_bosque))\n",
    "    #print(\"Accuracy tree:\",metrics.accuracy_score(y_test, y_pred_tree))\n",
    "    print(\"Accuracy gnd:\",metrics.accuracy_score(y_test, y_pred_gnd))\n",
    "    print(\"Accuracy svc:\",metrics.accuracy_score(y_test, y_pred_svc))\n",
    "    print(\"Accuracy gbc:\",metrics.accuracy_score(y_test, y_pred_gbc))\n",
    "    \n",
    "\n",
    "\n",
    "    # Your code here:\n",
    "    print(\"matriz de confusion lineal\",\"\\n\",confusion_matrix(y_test, y_predlr))\n",
    "    print(\"matriz de confusion vecino3\",\"\\n\",confusion_matrix(y_test, y_pred_neigh3))\n",
    "    print(\"matriz de confusion vecino5\",\"\\n\",confusion_matrix(y_test, y_pred_neigh5))\n",
    "    print(\"matriz de confusion bosque\",\"\\n\",confusion_matrix(y_test, y_pred_bosque))\n",
    "    print(\"matriz de confusion gnd\",\"\\n\",confusion_matrix(y_test, y_pred_gnd))\n",
    "    print(\"matriz de confusion svc\",\"\\n\",confusion_matrix(y_test, y_pred_svc))\n",
    "    print(\"matriz de confusion gbc\",\"\\n\", confusion_matrix(y_test, y_pred_gbc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se visualizan los distintos modelos y se ven que los mejores son el modelo lineal, el RandomForestClassifier\n",
    "# y el modelo gbc\n",
    "modelos(encuesta_dum,\"ideologia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#en un modelo lineal veo que existen variables que no son significativas, por lo que lo mejor para el modelo es eliminarlas\n",
    "#además se puede apreciar como el modelo explica el 58,2 de la variable independiente\n",
    "results = smf.ols('ideologia ~  P2  + P4 + P801 + P802 + P803+ P804 +P1301 + P1302 + P1303 +  P1304 + P2001 +P2002 + P2003 + P2004 + CCAA_2 +CCAA_3 + CCAA_4 + CCAA_5 + CCAA_6 + CCAA_7 + CCAA_8 + CCAA_9 + CCAA_10 + CCAA_11 + CCAA_12 + CCAA_13 + CCAA_14 + CCAA_15 + CCAA_16 + CCAA_17 + CCAA_18 + CCAA_19 + P0A_2   + P14R_2 + P14R_3 + P14R_4 + P14R_5 + P14R_6 + P14R_7 + P14R_8 + P14R_9 + P14R_11 +  P14R_12 + P14R_17 + P14R_18 + P14R_95 + P14R_97  + P26_2 + P26_3 + P26_4 + P26_5 + P26_6  + P23_1 + P23_2 + P23_3 ', data=encuesta_dum).fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se eliminan aquellas variables que no son significativas para el modelo\n",
    "encuestatotal=encuesta_dum.drop(columns=[\"P1\", \"P3\",\"P27_2\",\"P28_2\",\"P28_3\",\"TAMUNI\",\"ESTUDIOS_2\",\"ESTUDIOS_3\",\"ESTUDIOS_4\",\"ESTUDIOS_5\",\"ESTUDIOS_6\",\"P22_2\",\"P25_2\" , \"P25_3\" , \"P25_4\" , \"P25_5\" , \"P25_6\", \"P25_7\",\"P27_2\"  , \"P28_2\" , \"P28_3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se visualizan los modelos sin las variables no representativas \n",
    "modelos(encuestatotal,\"ideologia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdasfasd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se realiza un grid para conocer cuales son los mejores parametro con el modelo \n",
    "X=encuestatotal.loc[:,encuestatotal.columns!='ideologia']\n",
    "y=encuestatotal['ideologia']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param = {  \n",
    "    'n_estimators': [10,100,1000],\n",
    "    'criterion': ['gini', 'entropy'],   \n",
    "    'bootstrap': [True, False]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_sr = GridSearchCV(estimator=RandomForestClassifier(n_estimators=100),  \n",
    "                    param_grid=grid_param,\n",
    "                     scoring='accuracy',\n",
    "                     cv=3,\n",
    "                     n_jobs=-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_sr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters = gd_sr.best_params_ \n",
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_result = gd_sr.best_score_  \n",
    "best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Una vez conseguido un modelo que es óptimo se realiza un prueba con un valor random del test\n",
    "def get_random_data(dataset):\n",
    "    return dataset.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_encuesta=get_random_data(X_test)\n",
    "random_encuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bosque1000e=RandomForestClassifier(n_estimators=1000, criterion='entropy')\n",
    "bosque1000e.fit(X_train, y_train)\n",
    "y_pred_bosque1000e= bosque1000e.predict(X_test)\n",
    "print(\"Accuracy bosque1000e:\",metrics.accuracy_score(y_test, y_pred_bosque1000e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=bosque1000e.predict(random_encuesta)\n",
    "y_real=y[random_encuesta.index[0]]\n",
    "y_pred_proba=bosque1000e.predict_proba(random_encuesta)\n",
    "print(y_pred,y_real,y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters = 3)\n",
    "temp_kmeans = kmeans.fit(encuestatotal)\n",
    "encuestaKMeans=encuestatotal\n",
    "encuestaKMeans['labels'] = temp_kmeans.labels_\n",
    "encuestatotal.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bla= pd.crosstab(encuestaKMeans.ideologia, encuestaKMeans.labels)\n",
    "bla[\"total\"]=bla.T.sum()\n",
    "bla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "cluster = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward')  \n",
    "temp_AGG=cluster.fit_predict(encuestatotal)\n",
    "encuestaAGG=encuestatotal\n",
    "encuestaAGG['AGG'] = temp_AGG\n",
    "encuestatotal.AGG.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bla2= pd.crosstab(encuestaAGG.ideologia, encuestaAGG.AGG)\n",
    "bla2[\"total\"]=bla.T.sum()\n",
    "bla2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "customers_columns = [col for col in encuestatotal.columns.values if col not in ['ideologia']]\n",
    "customers_sample = encuestatotal[customers_columns].sample(n=100)\n",
    "hier_clust = AgglomerativeClustering(n_clusters=4,affinity='euclidean',linkage='complete')\n",
    "customers_hier = hier_clust.fit(customers_sample)\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_dendrogram(model, **kwargs):\n",
    "\n",
    "    # Children of hierarchical clustering\n",
    "    children = model.children_\n",
    "\n",
    "    # Distances between each pair of children\n",
    "    # Since we don't have this information, we can use a uniform one for plotting\n",
    "    distance = np.arange(children.shape[0])\n",
    "\n",
    "    # The number of observations contained in each cluster level\n",
    "    no_of_observations = np.arange(2, children.shape[0]+2)\n",
    "\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "    linkage_matrix = np.column_stack([children, distance, no_of_observations]).astype(float)\n",
    "\n",
    "    # Plot the corresponding dendrogram\n",
    "    dendrogram(linkage_matrix, **kwargs)\n",
    "    \n",
    "plot_dendrogram(customers_hier)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos(encuestaKMeans,\"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encuestaKMeans.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos(encuestaAGG,\"AGG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
